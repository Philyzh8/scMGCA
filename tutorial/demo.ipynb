{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster analysis\n",
    "In this tutorial, we will perform the entire `scMGCA` cluster analysis using the Qx Bladder dataset dataset (can be downloaded <a href=\"https://drive.google.com/drive/folders/1BIZxZNbouPtGf_cyu7vM44G5EcbxECeu\">here</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from spektral.layers import GraphConv\n",
    "from sklearn import metrics\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "# scMGCA module\n",
    "from scMGCA.preprocess import *\n",
    "from scMGCA.utils import *\n",
    "from scMGCA.scmgca import SCMGCA, SCMGCAL\n",
    "from scMGCA.losses import *\n",
    "from scMGCA.graph_function import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"train\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"--dataname\", default = \"Quake_10x_Bladder\", type = str)\n",
    "parser.add_argument(\"--highly_genes\", default = 500, type=int)\n",
    "parser.add_argument(\"--pretrain_epochs\", default = 1000, type=int)\n",
    "parser.add_argument(\"--maxiter\", default = 300, type=int)\n",
    "args = parser.parse_args(args=['--dataname', 'Quake_10x_Bladder', '--highly_genes', '500', '--pretrain_epochs', '1000', '--maxiter', '300'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell number: 2500\n",
      "Gene number 23341\n",
      "Cluster number: 4\n"
     ]
    }
   ],
   "source": [
    "data = './dataset/'+args.dataname+'/data.h5'\n",
    "x, y = prepro(data)\n",
    "cluster_number = len(np.unique(y))\n",
    "print(\"Cell number:\", x.shape[0])\n",
    "print(\"Gene number\",x.shape[1])        \n",
    "print(\"Cluster number:\", cluster_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ceil(x).astype(np.int)\n",
    "adata = sc.AnnData(x)\n",
    "adata.obs['Group'] = y\n",
    "adata = normalize(adata, copy=True, highly_genes=args.highly_genes, size_factors=True, normalize_input=True, logtrans_input=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct cell graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = adata.X\n",
    "adj = get_adj(count)\n",
    "adj_n = GraphConv.preprocess(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10  Mult_loss: 0.0029011532   A_rec_loss: 0.31470138\n",
      "Epoch 20  Mult_loss: -0.015144596   A_rec_loss: 0.25908032\n",
      "Epoch 30  Mult_loss: -0.031327844   A_rec_loss: 0.15848605\n",
      "Epoch 40  Mult_loss: -0.051763695   A_rec_loss: 0.033741966\n",
      "Epoch 50  Mult_loss: -0.08169778   A_rec_loss: 0.022088172\n",
      "Epoch 60  Mult_loss: -0.1273609   A_rec_loss: 0.01647526\n",
      "Epoch 70  Mult_loss: -0.20676383   A_rec_loss: 0.014043791\n",
      "Epoch 80  Mult_loss: -0.37768197   A_rec_loss: 0.013985698\n",
      "Epoch 90  Mult_loss: -0.78664976   A_rec_loss: 0.01526031\n",
      "Epoch 100  Mult_loss: -1.5655493   A_rec_loss: 0.016171148\n",
      "Epoch 110  Mult_loss: -1.9093715   A_rec_loss: 0.014860538\n",
      "Epoch 120  Mult_loss: -2.0988972   A_rec_loss: 0.013071854\n",
      "Epoch 130  Mult_loss: -2.1883917   A_rec_loss: 0.012399688\n",
      "Epoch 140  Mult_loss: -2.2425332   A_rec_loss: 0.012110037\n",
      "Epoch 150  Mult_loss: -2.2792387   A_rec_loss: 0.011897248\n",
      "Epoch 160  Mult_loss: -2.3088083   A_rec_loss: 0.01175571\n",
      "Epoch 170  Mult_loss: -2.3341951   A_rec_loss: 0.011648619\n",
      "Epoch 180  Mult_loss: -2.3597252   A_rec_loss: 0.011557204\n",
      "Epoch 190  Mult_loss: -2.388705   A_rec_loss: 0.011518687\n",
      "Epoch 200  Mult_loss: -2.4175255   A_rec_loss: 0.011512126\n",
      "Epoch 210  Mult_loss: -2.438472   A_rec_loss: 0.011513872\n",
      "Epoch 220  Mult_loss: -2.451831   A_rec_loss: 0.011498474\n",
      "Epoch 230  Mult_loss: -2.4613357   A_rec_loss: 0.011474237\n",
      "Epoch 240  Mult_loss: -2.4687855   A_rec_loss: 0.01144738\n",
      "Epoch 250  Mult_loss: -2.474939   A_rec_loss: 0.011419134\n",
      "Epoch 260  Mult_loss: -2.4802058   A_rec_loss: 0.011385784\n",
      "Epoch 270  Mult_loss: -2.484871   A_rec_loss: 0.011345112\n",
      "Epoch 280  Mult_loss: -2.4891403   A_rec_loss: 0.011294946\n",
      "Epoch 290  Mult_loss: -2.4931092   A_rec_loss: 0.011243563\n",
      "Epoch 300  Mult_loss: -2.4968793   A_rec_loss: 0.011173209\n",
      "Epoch 310  Mult_loss: -2.5004637   A_rec_loss: 0.0110895615\n",
      "Epoch 320  Mult_loss: -2.503984   A_rec_loss: 0.011012025\n",
      "Epoch 330  Mult_loss: -2.507331   A_rec_loss: 0.010954946\n",
      "Epoch 340  Mult_loss: -2.5105343   A_rec_loss: 0.010897517\n",
      "Epoch 350  Mult_loss: -2.5136194   A_rec_loss: 0.010835642\n",
      "Epoch 360  Mult_loss: -2.5166378   A_rec_loss: 0.010765381\n",
      "Epoch 370  Mult_loss: -2.5196013   A_rec_loss: 0.010667803\n",
      "Epoch 380  Mult_loss: -2.5225365   A_rec_loss: 0.010564978\n",
      "Epoch 390  Mult_loss: -2.5253787   A_rec_loss: 0.010475962\n",
      "Epoch 400  Mult_loss: -2.5282974   A_rec_loss: 0.010398303\n",
      "Epoch 410  Mult_loss: -2.5312207   A_rec_loss: 0.010338903\n",
      "Epoch 420  Mult_loss: -2.534238   A_rec_loss: 0.010277308\n",
      "Epoch 430  Mult_loss: -2.537207   A_rec_loss: 0.010227648\n",
      "Epoch 440  Mult_loss: -2.540208   A_rec_loss: 0.010181075\n",
      "Epoch 450  Mult_loss: -2.5433047   A_rec_loss: 0.010140677\n",
      "Epoch 460  Mult_loss: -2.546466   A_rec_loss: 0.010099447\n",
      "Epoch 470  Mult_loss: -2.5495925   A_rec_loss: 0.010059089\n",
      "Epoch 480  Mult_loss: -2.5526297   A_rec_loss: 0.010022443\n",
      "Epoch 490  Mult_loss: -2.55567   A_rec_loss: 0.009986782\n",
      "Epoch 500  Mult_loss: -2.5586085   A_rec_loss: 0.009960185\n",
      "Epoch 510  Mult_loss: -2.5618503   A_rec_loss: 0.009935979\n",
      "Epoch 520  Mult_loss: -2.5650632   A_rec_loss: 0.009919548\n",
      "Epoch 530  Mult_loss: -2.568307   A_rec_loss: 0.00990537\n",
      "Epoch 540  Mult_loss: -2.5716412   A_rec_loss: 0.009891308\n",
      "Epoch 550  Mult_loss: -2.574933   A_rec_loss: 0.009879578\n",
      "Epoch 560  Mult_loss: -2.578341   A_rec_loss: 0.009865332\n",
      "Epoch 570  Mult_loss: -2.581766   A_rec_loss: 0.009857192\n",
      "Epoch 580  Mult_loss: -2.5851147   A_rec_loss: 0.009845449\n",
      "Epoch 590  Mult_loss: -2.5885396   A_rec_loss: 0.009834188\n",
      "Epoch 600  Mult_loss: -2.591899   A_rec_loss: 0.009823178\n",
      "Epoch 610  Mult_loss: -2.5952656   A_rec_loss: 0.009810403\n",
      "Epoch 620  Mult_loss: -2.5985699   A_rec_loss: 0.009796745\n",
      "Epoch 630  Mult_loss: -2.6019182   A_rec_loss: 0.009782623\n",
      "Epoch 640  Mult_loss: -2.6052117   A_rec_loss: 0.009769757\n",
      "Epoch 650  Mult_loss: -2.6084805   A_rec_loss: 0.009756817\n",
      "Epoch 660  Mult_loss: -2.6117013   A_rec_loss: 0.009734638\n",
      "Epoch 670  Mult_loss: -2.614823   A_rec_loss: 0.009716543\n",
      "Epoch 680  Mult_loss: -2.6179802   A_rec_loss: 0.009701961\n",
      "Epoch 690  Mult_loss: -2.6209702   A_rec_loss: 0.009685964\n",
      "Epoch 700  Mult_loss: -2.6238909   A_rec_loss: 0.009670351\n",
      "Epoch 710  Mult_loss: -2.626701   A_rec_loss: 0.009660325\n",
      "Epoch 720  Mult_loss: -2.629546   A_rec_loss: 0.0096505955\n",
      "Epoch 730  Mult_loss: -2.6322308   A_rec_loss: 0.009643749\n",
      "Epoch 740  Mult_loss: -2.635036   A_rec_loss: 0.009637518\n",
      "Epoch 750  Mult_loss: -2.6377492   A_rec_loss: 0.009633631\n",
      "Epoch 760  Mult_loss: -2.6402767   A_rec_loss: 0.009628468\n",
      "Epoch 770  Mult_loss: -2.6429396   A_rec_loss: 0.009624722\n",
      "Epoch 780  Mult_loss: -2.6454167   A_rec_loss: 0.009619084\n",
      "Epoch 790  Mult_loss: -2.648008   A_rec_loss: 0.009614992\n",
      "Epoch 800  Mult_loss: -2.6504383   A_rec_loss: 0.009611111\n",
      "Epoch 810  Mult_loss: -2.6530018   A_rec_loss: 0.009605144\n",
      "Epoch 820  Mult_loss: -2.6554549   A_rec_loss: 0.009601196\n",
      "Epoch 830  Mult_loss: -2.6577747   A_rec_loss: 0.009597088\n",
      "Epoch 840  Mult_loss: -2.6603258   A_rec_loss: 0.009592004\n",
      "Epoch 850  Mult_loss: -2.6627507   A_rec_loss: 0.0095884325\n",
      "Epoch 860  Mult_loss: -2.6651447   A_rec_loss: 0.009585454\n",
      "Epoch 870  Mult_loss: -2.6673844   A_rec_loss: 0.009583814\n",
      "Epoch 880  Mult_loss: -2.6698294   A_rec_loss: 0.009579841\n",
      "Epoch 890  Mult_loss: -2.6722207   A_rec_loss: 0.009578356\n",
      "Epoch 900  Mult_loss: -2.6745434   A_rec_loss: 0.009574379\n",
      "Epoch 910  Mult_loss: -2.6768467   A_rec_loss: 0.009571778\n",
      "Epoch 920  Mult_loss: -2.679267   A_rec_loss: 0.009569925\n",
      "Epoch 930  Mult_loss: -2.6815803   A_rec_loss: 0.009566946\n",
      "Epoch 940  Mult_loss: -2.6838799   A_rec_loss: 0.009563378\n",
      "Epoch 950  Mult_loss: -2.6862326   A_rec_loss: 0.009558857\n",
      "Epoch 960  Mult_loss: -2.6884918   A_rec_loss: 0.009554331\n",
      "Epoch 970  Mult_loss: -2.6908073   A_rec_loss: 0.009552558\n",
      "Epoch 980  Mult_loss: -2.693068   A_rec_loss: 0.009545364\n",
      "Epoch 990  Mult_loss: -2.6953423   A_rec_loss: 0.009539412\n",
      "Epoch 1000  Mult_loss: -2.6975663   A_rec_loss: 0.009536003\n",
      "Pre_train Finish!\n"
     ]
    }
   ],
   "source": [
    "model = SCMGCA(count, adj=adj, adj_n=adj_n)\n",
    "model.pre_train(epochs=args.pretrain_epochs)\n",
    "latent_pre = model.embedding(count, adj_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Mult_loss:  -2.6977754  A_rec_loss:  0.009536077  cluster_loss:  0.14840695\n",
      "Epoch 10  Mult_loss:  -2.5016093  A_rec_loss:  0.009309375  cluster_loss:  0.14243658\n",
      "Epoch 20  Mult_loss:  -2.5999277  A_rec_loss:  0.009281411  cluster_loss:  0.13151222\n",
      "Epoch 30  Mult_loss:  -2.6170561  A_rec_loss:  0.0092894565  cluster_loss:  0.11304958\n",
      "Epoch 40  Mult_loss:  -2.6233497  A_rec_loss:  0.009289366  cluster_loss:  0.09988786\n",
      "Epoch 50  Mult_loss:  -2.6266727  A_rec_loss:  0.009287632  cluster_loss:  0.09036012\n",
      "Epoch 60  Mult_loss:  -2.6317556  A_rec_loss:  0.009252352  cluster_loss:  0.08314127\n",
      "Epoch 70  Mult_loss:  -2.6360266  A_rec_loss:  0.009267595  cluster_loss:  0.077201374\n",
      "Epoch 80  Mult_loss:  -2.6396744  A_rec_loss:  0.009255022  cluster_loss:  0.0722112\n",
      "Epoch 90  Mult_loss:  -2.6436422  A_rec_loss:  0.009254993  cluster_loss:  0.06802508\n",
      "Epoch 100  Mult_loss:  -2.647798  A_rec_loss:  0.009276437  cluster_loss:  0.06441607\n",
      "Epoch 110  Mult_loss:  -2.652613  A_rec_loss:  0.009264581  cluster_loss:  0.061304737\n",
      "Epoch 120  Mult_loss:  -2.6576908  A_rec_loss:  0.009260395  cluster_loss:  0.058612537\n",
      "Epoch 130  Mult_loss:  -2.6611595  A_rec_loss:  0.009287737  cluster_loss:  0.056369044\n",
      "Epoch 140  Mult_loss:  -2.6658125  A_rec_loss:  0.009269866  cluster_loss:  0.054379053\n",
      "Epoch 150  Mult_loss:  -2.6702096  A_rec_loss:  0.009257545  cluster_loss:  0.052649047\n",
      "Epoch 160  Mult_loss:  -2.674398  A_rec_loss:  0.009256321  cluster_loss:  0.05104226\n",
      "Epoch 170  Mult_loss:  -2.676112  A_rec_loss:  0.009265389  cluster_loss:  0.04967633\n",
      "Epoch 180  Mult_loss:  -2.6815028  A_rec_loss:  0.009257524  cluster_loss:  0.04855913\n",
      "Epoch 190  Mult_loss:  -2.6856859  A_rec_loss:  0.009252053  cluster_loss:  0.047384694\n",
      "Epoch 200  Mult_loss:  -2.6894417  A_rec_loss:  0.009252381  cluster_loss:  0.046434242\n",
      "Epoch 210  Mult_loss:  -2.6929224  A_rec_loss:  0.009251158  cluster_loss:  0.04548648\n",
      "Epoch 220  Mult_loss:  -2.6970804  A_rec_loss:  0.009251926  cluster_loss:  0.044627417\n",
      "Epoch 230  Mult_loss:  -2.7001884  A_rec_loss:  0.009288997  cluster_loss:  0.04382617\n",
      "Epoch 240  Mult_loss:  -2.703233  A_rec_loss:  0.009289946  cluster_loss:  0.04314275\n",
      "Epoch 250  Mult_loss:  -2.7077985  A_rec_loss:  0.009289946  cluster_loss:  0.042438433\n",
      "Epoch 260  Mult_loss:  -2.7096925  A_rec_loss:  0.009289946  cluster_loss:  0.04176145\n",
      "Epoch 270  Mult_loss:  -2.7136111  A_rec_loss:  0.009289946  cluster_loss:  0.041201342\n",
      "Epoch 280  Mult_loss:  -2.7191837  A_rec_loss:  0.009289946  cluster_loss:  0.040637758\n",
      "Epoch 290  Mult_loss:  -2.7230098  A_rec_loss:  0.009289946  cluster_loss:  0.040089436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    }
   ],
   "source": [
    "centers = init_center(args, latent_pre, adj_n, cluster_number)\n",
    "Cluster_predicted=model.train(epochs=args.maxiter, centers=centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI= 0.9802, ARI= 0.9900\n"
     ]
    }
   ],
   "source": [
    "y = list(map(int, y))\n",
    "Cluster_predicted.y_pred = np.array(Cluster_predicted.y_pred)\n",
    "nmi = metrics.normalized_mutual_info_score(y, Cluster_predicted.y_pred)\n",
    "ari = metrics.adjusted_rand_score(y, Cluster_predicted.y_pred)\n",
    "print('NMI= %.4f, ARI= %.4f' % (nmi, ari))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4981b31b3740e087fbd6606ec2a9ef21ac0e21fb1222d6521f4ab85985e6372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
